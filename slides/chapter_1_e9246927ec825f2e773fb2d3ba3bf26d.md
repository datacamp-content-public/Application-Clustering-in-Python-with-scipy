---
title: Insert title here
key: e9246927ec825f2e773fb2d3ba3bf26d

---
## Data Preparation for Cluster Analysis

```yaml
type: "TitleSlide"
key: "da8652ce0b"
```

`@lower_third`

name: Shaumik Daityari
title: Business Analyst


`@script`



---
## Why do we need to prepare data for clustering?

```yaml
type: "FullSlide"
key: "b008ec98f2"
```

`@part1`
- Data in raw form may lead to bias in clustering
- Clusters may be heavily dependent on one variable

Two techniques:
- Standardization of individual variables
- PCA to address correlation between variables


`@script`



---
## Standardization of Data

```yaml
type: "FullSlide"
key: "312f450e14"
```

`@part1`
- Variables have incomparable units (product dimensions in cm, price in $)
- Variables with same units have vastly different variances (expenditures on cereals, fuel)
- Standardization: Process of rescaling data to a mean of 0 and standard deviation of 1

> x_new = (x - μ)/ σ


`@script`



---
## Illustration: Standardization of Data

```yaml
type: "FullCodeSlide"
key: "0c4191a5ec"
```

`@part1`
`data = [5, 1, 3, 3, 2, 3, 3, 8, 1, 2, 2, 3, 5]`

```
from sklearn import preprocessing
import numpy as np

scaler = preprocessing.StandardScaler()

data_array = np.array(data)
data_array = data_array.reshape(-1, 1)

# Fit your data on tbhe scaler object
scaled_data = scaler.fit_transform(data_array)
```

`array([[ 1.00701763],
       [-1.1748539 ],
       [-0.08391814],
       [-0.08391814],
       [-0.62938602],
       [-0.08391814],
       [-0.08391814],
       [ 2.64342128],
       [-1.1748539 ],
       [-0.62938602],
       [-0.62938602],
       [-0.08391814],
       [ 1.00701763]])`


`@script`



---
## Correlated Variables

```yaml
type: "FullSlide"
key: "bf9d7f1f54"
```

`@part1`



`@script`



---
## Next up: Some DIY Exercises

```yaml
type: "FinalSlide"
key: "c1cf5900ab"
```

`@script`


